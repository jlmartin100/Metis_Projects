{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Redux\n",
    "\n",
    "I had initially hoped that either the Random Forest or XGBoost models with over or undersampling might lend some support for feature selection that I could then use to dig into a logistic regression model, which seemed due to the binary nature of the problem to be the model best suited to this data.  Unfortunately, RF and XGB did not really lend any clarity here.  \n",
    "\n",
    "I attempted to build a model with smaller subsets of the data, including respectively only hospitalized patients, and only immunosuppressed patients.  I additionally worked on some feature engineering, to try to draw out any correlations specifically around the `inmsupr` feature in the data.  I also attempted to use GridSearchCV to aid in finding the best possible combination of C and L1 versus L2 penalty for regularization. In addition, I applied oversampling and undersampling with the logistic regression model, in the hopes that this might provide better results.\n",
    "\n",
    "However, after all of these experiments, it became clear that my original baseline logistic regression model, from my Minimum Viable Product in Notebook 04, had better validation results than any other model, and ultimately better test results as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospitalization Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_hosp = pd.read_json('covid_hosp.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [ 'sex','patient_type', 'pneumonia', 'diabetes', 'copd', 'asthma', 'inmsupr',\n",
    "       'hypertension', 'other_disease', 'cardiovascular', 'obesity',\n",
    "       'renal_chronic', 'tobacco', 'pregnancy', 'icu', 'intubed', 'covid_res',\n",
    "       'contact_other_covid', 'passed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_hosp[categoricals] = covid_hosp[categoricals].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120026, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_hosp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "hosp_train, hosp_test = train_test_split(covid_hosp, test_size=0.2, random_state=33, stratify=covid_hosp['passed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "hosp_train, hosp_val = train_test_split(hosp_train, test_size=0.2, random_state=33, stratify=hosp_train['passed'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immunosuppressed Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_immun = pd.read_json('covid_immun.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_immun[categoricals] = covid_immun[categoricals].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8904, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_immun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "immun_train, immun_test = train_test_split(covid_immun, test_size=0.2, random_state=33, stratify=covid_immun['passed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "immun_train, immun_val = train_test_split(immun_train, test_size=0.2, random_state=33, stratify=immun_train['passed'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineered Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_feat = pd.read_json('covid_hosp_feats.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120026, 29)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sex', 'patient_type', 'entry_date', 'date_symptoms', 'date_died',\n",
       "       'intubed', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd',\n",
       "       'asthma', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular',\n",
       "       'obesity', 'renal_chronic', 'tobacco', 'contact_other_covid',\n",
       "       'covid_res', 'icu', 'passed', 'comorb_count', 'imm_comorb',\n",
       "       'imm_covid_pos', 'imm_other_dis', 'imm_lung_disease'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_res = pd.get_dummies(covid_feat['covid_res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  0  1  0\n",
       "1  0  1  0\n",
       "2  0  1  0\n",
       "3  0  1  0\n",
       "4  0  1  0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_feat = pd.get_dummies(covid_feat, columns=['covid_res'], drop_first=True, prefix='covid_res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>patient_type</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>date_symptoms</th>\n",
       "      <th>date_died</th>\n",
       "      <th>intubed</th>\n",
       "      <th>pneumonia</th>\n",
       "      <th>age</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_other_covid</th>\n",
       "      <th>icu</th>\n",
       "      <th>passed</th>\n",
       "      <th>comorb_count</th>\n",
       "      <th>imm_comorb</th>\n",
       "      <th>imm_covid_pos</th>\n",
       "      <th>imm_other_dis</th>\n",
       "      <th>imm_lung_disease</th>\n",
       "      <th>covid_res_1</th>\n",
       "      <th>covid_res_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18be58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-19T00:00:00.000Z</td>\n",
       "      <td>2020-06-19T00:00:00.000Z</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c3c05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-04T00:00:00.000Z</td>\n",
       "      <td>2020-04-28T00:00:00.000Z</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06861b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-05T00:00:00.000Z</td>\n",
       "      <td>2020-04-29T00:00:00.000Z</td>\n",
       "      <td>08-05-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e0b21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-14T00:00:00.000Z</td>\n",
       "      <td>2020-06-14T00:00:00.000Z</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16b611</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-20T00:00:00.000Z</td>\n",
       "      <td>2020-04-10T00:00:00.000Z</td>\n",
       "      <td>30-04-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sex  patient_type                entry_date  \\\n",
       "0  18be58    1             1  2020-06-19T00:00:00.000Z   \n",
       "1  0c3c05    0             1  2020-05-04T00:00:00.000Z   \n",
       "2  06861b    1             1  2020-05-05T00:00:00.000Z   \n",
       "3  1e0b21    0             1  2020-06-14T00:00:00.000Z   \n",
       "4  16b611    1             1  2020-04-20T00:00:00.000Z   \n",
       "\n",
       "              date_symptoms   date_died  intubed  pneumonia  age  pregnancy  \\\n",
       "0  2020-06-19T00:00:00.000Z  9999-99-99        0          1   57          0   \n",
       "1  2020-04-28T00:00:00.000Z  9999-99-99        0          0   66          0   \n",
       "2  2020-04-29T00:00:00.000Z  08-05-2020        0          0   55          0   \n",
       "3  2020-06-14T00:00:00.000Z  9999-99-99        0          0   35          0   \n",
       "4  2020-04-10T00:00:00.000Z  30-04-2020        0          1   44          0   \n",
       "\n",
       "   ...  contact_other_covid  icu  passed  comorb_count  imm_comorb  \\\n",
       "0  ...                    1    0       0             3           0   \n",
       "1  ...                    0    0       0             0           0   \n",
       "2  ...                    0    0       1             2           0   \n",
       "3  ...                    0    0       0             1           0   \n",
       "4  ...                    0    0       1             0           0   \n",
       "\n",
       "   imm_covid_pos  imm_other_dis  imm_lung_disease  covid_res_1  covid_res_2  \n",
       "0              0              0                 0            1            0  \n",
       "1              0              0                 0            1            0  \n",
       "2              0              0                 0            1            0  \n",
       "3              0              0                 0            1            0  \n",
       "4              0              0                 0            1            0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sex', 'patient_type', 'entry_date', 'date_symptoms', 'date_died',\n",
       "       'intubed', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd',\n",
       "       'asthma', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular',\n",
       "       'obesity', 'renal_chronic', 'tobacco', 'contact_other_covid', 'icu',\n",
       "       'passed', 'comorb_count', 'imm_comorb', 'imm_covid_pos',\n",
       "       'imm_other_dis', 'imm_lung_disease', 'covid_res_1', 'covid_res_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [ 'sex','patient_type', 'pneumonia', 'diabetes', 'copd', 'asthma', 'inmsupr',\n",
    "       'hypertension', 'other_disease', 'cardiovascular', 'obesity',\n",
    "       'renal_chronic', 'tobacco', 'pregnancy', 'icu', 'intubed',\n",
    "       'contact_other_covid', 'passed', 'covid_res_1', 'covid_res_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_feat[categoricals] = covid_feat[categoricals].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "\n",
    "feat_train, feat_test = train_test_split(covid_feat, test_size=0.2, random_state=33, stratify=covid_feat['passed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "feat_train, feat_val = train_test_split(feat_train, test_size=0.2, random_state=33, stratify=feat_train['passed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sex', 'intubed', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd',\n",
    "       'asthma', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular',\n",
    "       'obesity', 'renal_chronic', 'tobacco', 'contact_other_covid', 'icu', 'comorb_count', 'imm_comorb',\n",
    "       'imm_covid_pos', 'imm_other_dis', 'imm_lung_disease','covid_res_1', 'covid_res_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline, no penalty\n",
    "feat_lr = LogisticRegression(solver='saga', max_iter=1000)\n",
    "xtrain = feat_train[features]\n",
    "ytrain = feat_train['passed']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "feat_lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13271,   821],\n",
       "       [ 3725,  1387]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xval = scaler.transform(feat_val[features])\n",
    "yval = feat_val['passed']\n",
    "lr_preds = feat_lr.predict(xval)\n",
    "lr_conf = confusion_matrix(yval, lr_preds)\n",
    "lr_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490793\n",
      "         Iterations 12\n"
     ]
    }
   ],
   "source": [
    "# statsmodels for comparison\n",
    "feat_sm = sm.Logit(ytrain, sm.add_constant(xtrain))\n",
    "feat_sm = feat_sm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>passed</td>      <th>  No. Observations:  </th>  <td> 76816</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 76792</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    23</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 08 Feb 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.1530</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>08:38:45</td>     <th>  Log-Likelihood:    </th> <td> -37701.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -44509.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.2797</td> <td>    0.010</td> <td> -124.569</td> <td> 0.000</td> <td>   -1.300</td> <td>   -1.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1315</td> <td>    0.009</td> <td>   14.094</td> <td> 0.000</td> <td>    0.113</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.3896</td> <td>    0.009</td> <td>   41.344</td> <td> 0.000</td> <td>    0.371</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.2787</td> <td>    0.010</td> <td>   28.268</td> <td> 0.000</td> <td>    0.259</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.6125</td> <td>    0.012</td> <td>   52.736</td> <td> 0.000</td> <td>    0.590</td> <td>    0.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0991</td> <td>    0.021</td> <td>   -4.647</td> <td> 0.000</td> <td>   -0.141</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0425</td> <td> 2.35e+05</td> <td> 1.81e-07</td> <td> 1.000</td> <td> -4.6e+05</td> <td>  4.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0129</td> <td> 1.07e+05</td> <td>-1.21e-07</td> <td> 1.000</td> <td>-2.09e+05</td> <td> 2.09e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0493</td> <td> 8.17e+04</td> <td>-6.03e-07</td> <td> 1.000</td> <td> -1.6e+05</td> <td>  1.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0963</td> <td>    0.024</td> <td>    4.058</td> <td> 0.000</td> <td>    0.050</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0258</td> <td> 2.43e+05</td> <td> 1.06e-07</td> <td> 1.000</td> <td>-4.77e+05</td> <td> 4.77e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0556</td> <td> 1.22e+05</td> <td> 4.56e-07</td> <td> 1.000</td> <td>-2.39e+05</td> <td> 2.39e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0149</td> <td> 1.14e+05</td> <td>-1.31e-07</td> <td> 1.000</td> <td>-2.23e+05</td> <td> 2.23e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0461</td> <td>    0.009</td> <td>    5.166</td> <td> 0.000</td> <td>    0.029</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0720</td> <td> 1.22e+05</td> <td> 5.88e-07</td> <td> 1.000</td> <td> -2.4e+05</td> <td>  2.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0164</td> <td>    0.009</td> <td>   -1.822</td> <td> 0.069</td> <td>   -0.034</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.2869</td> <td>    0.011</td> <td>  -27.016</td> <td> 0.000</td> <td>   -0.308</td> <td>   -0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0094</td> <td>    0.010</td> <td>   -0.950</td> <td> 0.342</td> <td>   -0.029</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0472</td> <td> 5.24e+05</td> <td> 9.01e-08</td> <td> 1.000</td> <td>-1.03e+06</td> <td> 1.03e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0377</td> <td>    0.018</td> <td>   -2.092</td> <td> 0.036</td> <td>   -0.073</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0009</td> <td>    0.011</td> <td>    0.076</td> <td> 0.939</td> <td>   -0.021</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.0007</td> <td>    0.012</td> <td>   -0.060</td> <td> 0.952</td> <td>   -0.024</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0216</td> <td>    0.017</td> <td>   -1.298</td> <td> 0.194</td> <td>   -0.054</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.4517</td> <td>    0.011</td> <td>   40.731</td> <td> 0.000</td> <td>    0.430</td> <td>    0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.1311</td> <td>    0.012</td> <td>  -10.682</td> <td> 0.000</td> <td>   -0.155</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 passed   No. Observations:                76816\n",
       "Model:                          Logit   Df Residuals:                    76792\n",
       "Method:                           MLE   Df Model:                           23\n",
       "Date:                Mon, 08 Feb 2021   Pseudo R-squ.:                  0.1530\n",
       "Time:                        08:38:45   Log-Likelihood:                -37701.\n",
       "converged:                       True   LL-Null:                       -44509.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.2797      0.010   -124.569      0.000      -1.300      -1.260\n",
       "x1             0.1315      0.009     14.094      0.000       0.113       0.150\n",
       "x2             0.3896      0.009     41.344      0.000       0.371       0.408\n",
       "x3             0.2787      0.010     28.268      0.000       0.259       0.298\n",
       "x4             0.6125      0.012     52.736      0.000       0.590       0.635\n",
       "x5            -0.0991      0.021     -4.647      0.000      -0.141      -0.057\n",
       "x6             0.0425   2.35e+05   1.81e-07      1.000    -4.6e+05     4.6e+05\n",
       "x7            -0.0129   1.07e+05  -1.21e-07      1.000   -2.09e+05    2.09e+05\n",
       "x8            -0.0493   8.17e+04  -6.03e-07      1.000    -1.6e+05     1.6e+05\n",
       "x9             0.0963      0.024      4.058      0.000       0.050       0.143\n",
       "x10            0.0258   2.43e+05   1.06e-07      1.000   -4.77e+05    4.77e+05\n",
       "x11            0.0556   1.22e+05   4.56e-07      1.000   -2.39e+05    2.39e+05\n",
       "x12           -0.0149   1.14e+05  -1.31e-07      1.000   -2.23e+05    2.23e+05\n",
       "x13            0.0461      0.009      5.166      0.000       0.029       0.064\n",
       "x14            0.0720   1.22e+05   5.88e-07      1.000    -2.4e+05     2.4e+05\n",
       "x15           -0.0164      0.009     -1.822      0.069      -0.034       0.001\n",
       "x16           -0.2869      0.011    -27.016      0.000      -0.308      -0.266\n",
       "x17           -0.0094      0.010     -0.950      0.342      -0.029       0.010\n",
       "x18            0.0472   5.24e+05   9.01e-08      1.000   -1.03e+06    1.03e+06\n",
       "x19           -0.0377      0.018     -2.092      0.036      -0.073      -0.002\n",
       "x20            0.0009      0.011      0.076      0.939      -0.021       0.023\n",
       "x21           -0.0007      0.012     -0.060      0.952      -0.024       0.023\n",
       "x22           -0.0216      0.017     -1.298      0.194      -0.054       0.011\n",
       "x23            0.4517      0.011     40.731      0.000       0.430       0.473\n",
       "x24           -0.1311      0.012    -10.682      0.000      -0.155      -0.107\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_sm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.27966392]),\n",
       " array([[ 0.1314572 ,  0.3895093 ,  0.27866462,  0.61238222, -0.09905339,\n",
       "          0.04249466, -0.01288198, -0.04931456,  0.09618228,  0.02576786,\n",
       "          0.05556881, -0.01486286,  0.04605757,  0.07194404, -0.01636137,\n",
       "         -0.28688245, -0.0094236 ,  0.04720759, -0.03764559,  0.00089342,\n",
       "         -0.00074813, -0.02153534,  0.45165612, -0.13105201]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_lr.intercept_, feat_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85     56369\n",
      "           1       0.63      0.27      0.38     20447\n",
      "\n",
      "    accuracy                           0.76     76816\n",
      "   macro avg       0.70      0.61      0.62     76816\n",
      "weighted avg       0.74      0.76      0.73     76816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on training set\n",
    "print(classification_report(ytrain, feat_lr.predict(xtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85     14092\n",
      "           1       0.63      0.27      0.38      5112\n",
      "\n",
      "    accuracy                           0.76     19204\n",
      "   macro avg       0.70      0.61      0.62     19204\n",
      "weighted avg       0.74      0.76      0.73     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on validation set\n",
    "print(classification_report(yval, feat_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98244384, 0.01755616],\n",
       "       [0.80990819, 0.19009181],\n",
       "       [0.41001012, 0.58998988],\n",
       "       [0.92090796, 0.07909204],\n",
       "       [0.75076525, 0.24923475],\n",
       "       [0.95976289, 0.04023711],\n",
       "       [0.85676989, 0.14323011],\n",
       "       [0.93328275, 0.06671725],\n",
       "       [0.79761172, 0.20238828],\n",
       "       [0.77265747, 0.22734253]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_lr.predict_proba(xval)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Imbalanced Data in the Feature Engineered Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 56369, 1: 56369})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=33)\n",
    "x_resampled, y_resampled = ros.fit_sample(xtrain, ytrain)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversampled, no penalty\n",
    "osample_lr = LogisticRegression(solver='saga', max_iter=1000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_resampled = scaler.fit_transform(x_resampled)\n",
    "osample_lr.fit(x_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8190, 5902],\n",
       "       [1087, 4025]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osample_preds = osample_lr.predict(xval)\n",
    "osample_conf = confusion_matrix(yval, osample_preds)\n",
    "osample_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68     56369\n",
      "           1       0.68      0.71      0.70     56369\n",
      "\n",
      "    accuracy                           0.69    112738\n",
      "   macro avg       0.69      0.69      0.69    112738\n",
      "weighted avg       0.69      0.69      0.69    112738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on training set\n",
    "print(classification_report(y_resampled, osample_lr.predict(x_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70     14092\n",
      "           1       0.41      0.79      0.54      5112\n",
      "\n",
      "    accuracy                           0.64     19204\n",
      "   macro avg       0.64      0.68      0.62     19204\n",
      "weighted avg       0.76      0.64      0.66     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on validation set - looks like overfitting to the training data\n",
    "# worse than without oversampling\n",
    "print(classification_report(yval, osample_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 56369, 1: 56369})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "x_smoted, y_smoted = SMOTE(random_state=32).fit_sample(xtrain, ytrain)\n",
    "Counter(y_smoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE oversampled, no penalty\n",
    "SMOTE_lr = LogisticRegression(solver='saga', max_iter=1000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_smoted = scaler.fit_transform(x_smoted)\n",
    "SMOTE_lr.fit(x_smoted, y_smoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8194, 5898],\n",
       "       [1090, 4022]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMOTE_preds = SMOTE_lr.predict(xval)\n",
    "SMOTE_conf = confusion_matrix(yval, SMOTE_preds)\n",
    "SMOTE_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68     56369\n",
      "           1       0.68      0.71      0.70     56369\n",
      "\n",
      "    accuracy                           0.69    112738\n",
      "   macro avg       0.69      0.69      0.69    112738\n",
      "weighted avg       0.69      0.69      0.69    112738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on training set\n",
    "print(classification_report(y_smoted, SMOTE_lr.predict(x_smoted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70     14092\n",
      "           1       0.41      0.79      0.54      5112\n",
      "\n",
      "    accuracy                           0.64     19204\n",
      "   macro avg       0.64      0.68      0.62     19204\n",
      "weighted avg       0.76      0.64      0.66     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on validation set\n",
    "# same as basic oversampling, worse than non-sampled\n",
    "print(classification_report(yval, SMOTE_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADASYN (Adaptive Synthetic Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 56369, 1: 59101})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "X_adasyn, y_adasyn = ADASYN(random_state=33).fit_sample(xtrain, ytrain)\n",
    "Counter(y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADASYN oversampled, no penalty\n",
    "ADASYN_lr = LogisticRegression(solver='saga', max_iter=1000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_adasyn = scaler.fit_transform(X_adasyn)\n",
    "ADASYN_lr.fit(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7726, 6366],\n",
       "       [ 948, 4164]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADASYN_preds = ADASYN_lr.predict(xval)\n",
    "ADASYN_conf = confusion_matrix(yval, ADASYN_preds)\n",
    "ADASYN_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64     56369\n",
      "           1       0.66      0.71      0.68     59101\n",
      "\n",
      "    accuracy                           0.66    115470\n",
      "   macro avg       0.66      0.66      0.66    115470\n",
      "weighted avg       0.66      0.66      0.66    115470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on training set\n",
    "print(classification_report(y_adasyn, ADASYN_lr.predict(X_adasyn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68     14092\n",
      "           1       0.40      0.81      0.53      5112\n",
      "\n",
      "    accuracy                           0.62     19204\n",
      "   macro avg       0.64      0.68      0.61     19204\n",
      "weighted avg       0.76      0.62      0.64     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on validation set\n",
    "# nice improvement on recall, but took a hit on precision\n",
    "# maybe worth working on the penalization\n",
    "# look\n",
    "print(classification_report(yval, ADASYN_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex : [0.12977655]\n",
      "intubed : [0.32463395]\n",
      "pneumonia : [0.23820629]\n",
      "age : [0.52438052]\n",
      "pregnancy : [-0.07979762]\n",
      "diabetes : [0.04497495]\n",
      "copd : [-0.00560068]\n",
      "asthma : [-0.04568401]\n",
      "inmsupr : [0.10976532]\n",
      "hypertension : [0.01437715]\n",
      "other_disease : [0.05476367]\n",
      "cardiovascular : [-0.01118642]\n",
      "obesity : [0.03436354]\n",
      "renal_chronic : [0.06398638]\n",
      "tobacco : [-0.01713429]\n",
      "contact_other_covid : [-0.27611447]\n",
      "icu : [-0.00817442]\n",
      "comorb_count : [0.0443561]\n",
      "imm_comorb : [-0.03196222]\n",
      "imm_covid_pos : [-0.017127]\n",
      "imm_other_dis : [0.00394484]\n",
      "imm_lung_disease : [-0.02537926]\n",
      "covid_res_1 : [0.36981852]\n",
      "covid_res_2 : [-0.10330525]\n"
     ]
    }
   ],
   "source": [
    "for feature, coef in zip(feat_train[features], ADASYN_lr.coef_.T):\n",
    "    print(feature, ':', coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sex', array([ 0.12977655,  0.32463395,  0.23820629,  0.52438052, -0.07979762,\n",
      "        0.04497495, -0.00560068, -0.04568401,  0.10976532,  0.01437715,\n",
      "        0.05476367, -0.01118642,  0.03436354,  0.06398638, -0.01713429,\n",
      "       -0.27611447, -0.00817442,  0.0443561 , -0.03196222, -0.017127  ,\n",
      "        0.00394484, -0.02537926,  0.36981852, -0.10330525]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(features, ADASYN_lr.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADASYN_lr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0, max_iter=1000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADASYN oversampled, L2\n",
    "ADASYN_L2_lr = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0, max_iter=1000)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_adasyn = scaler.fit_transform(X_adasyn)\n",
    "ADASYN_L2_lr.fit(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7725, 6367],\n",
       "       [ 948, 4164]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADASYN_L2_preds = ADASYN_L2_lr.predict(xval)\n",
    "ADASYN_L2_conf = confusion_matrix(yval, ADASYN_L2_preds)\n",
    "ADASYN_L2_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7726, 6366],\n",
       "       [ 948, 4164]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADASYN_preds = ADASYN_lr.predict(xval)\n",
    "ADASYN_conf = confusion_matrix(yval, ADASYN_preds)\n",
    "ADASYN_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68     14092\n",
      "           1       0.40      0.81      0.53      5112\n",
      "\n",
      "    accuracy                           0.62     19204\n",
      "   macro avg       0.64      0.68      0.61     19204\n",
      "weighted avg       0.76      0.62      0.64     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval, ADASYN_L2_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68     14092\n",
      "           1       0.40      0.81      0.53      5112\n",
      "\n",
      "    accuracy                           0.62     19204\n",
      "   macro avg       0.64      0.68      0.61     19204\n",
      "weighted avg       0.76      0.62      0.64     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval, ADASYN_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=1, max_iter=1000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADASYN oversampled, L1\n",
    "ADASYN_L1_lr = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=1, max_iter=1000)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_adasyn = scaler.fit_transform(X_adasyn)\n",
    "ADASYN_L1_lr.fit(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7728, 6364],\n",
       "       [ 948, 4164]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADASYN_L1_preds = ADASYN_L1_lr.predict(xval)\n",
    "ADASYN_L1_conf = confusion_matrix(yval, ADASYN_L1_preds)\n",
    "ADASYN_L1_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68     14092\n",
      "           1       0.40      0.81      0.53      5112\n",
      "\n",
      "    accuracy                           0.62     19204\n",
      "   macro avg       0.64      0.68      0.61     19204\n",
      "weighted avg       0.76      0.62      0.64     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval, ADASYN_L1_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68     14092\n",
      "           1       0.40      0.81      0.53      5112\n",
      "\n",
      "    accuracy                           0.62     19204\n",
      "   macro avg       0.64      0.68      0.61     19204\n",
      "weighted avg       0.76      0.62      0.64     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval, ADASYN_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0.5, max_iter=1000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADASYN oversampled, L1-L2 balanced\n",
    "ADASYN_bal_lr = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5, max_iter=1000)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_adasyn = scaler.fit_transform(X_adasyn)\n",
    "ADASYN_bal_lr.fit(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7728, 6364],\n",
       "       [ 948, 4164]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADASYN_bal_preds = ADASYN_bal_lr.predict(xval)\n",
    "ADASYN_bal_conf = confusion_matrix(yval, ADASYN_bal_preds)\n",
    "ADASYN_bal_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68     14092\n",
      "           1       0.40      0.81      0.53      5112\n",
      "\n",
      "    accuracy                           0.62     19204\n",
      "   macro avg       0.64      0.68      0.61     19204\n",
      "weighted avg       0.76      0.62      0.64     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval, ADASYN_bal_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 20447, 1: 20447})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "x_under, y_under = RandomUnderSampler(random_state=33).fit_sample(xtrain, ytrain)\n",
    "Counter(y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled, no penalty\n",
    "under_lr = LogisticRegression(solver='saga', max_iter=1000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_under = scaler.fit_transform(x_under)\n",
    "under_lr.fit(x_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8214, 5878],\n",
       "       [1078, 4034]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_preds = under_lr.predict(xval)\n",
    "under_conf = confusion_matrix(yval, under_preds)\n",
    "under_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68     20447\n",
      "           1       0.68      0.71      0.70     20447\n",
      "\n",
      "    accuracy                           0.69     40894\n",
      "   macro avg       0.69      0.69      0.69     40894\n",
      "weighted avg       0.69      0.69      0.69     40894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on training set\n",
    "print(classification_report(y_under, under_lr.predict(x_under)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70     14092\n",
      "           1       0.41      0.79      0.54      5112\n",
      "\n",
      "    accuracy                           0.64     19204\n",
      "   macro avg       0.65      0.69      0.62     19204\n",
      "weighted avg       0.76      0.64      0.66     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring on validation set\n",
    "# very close to baseline model\n",
    "print(classification_report(yval, under_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70     14092\n",
      "           1       0.41      0.79      0.54      5112\n",
      "\n",
      "    accuracy                           0.64     19204\n",
      "   macro avg       0.64      0.68      0.62     19204\n",
      "weighted avg       0.76      0.64      0.66     19204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# base model scoring on validation set\n",
    "print(classification_report(yval, feat_lr.predict(xval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, log_loss, make_scorer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtraings = feat_train[strict_features]\n",
    "ytraings = feat_train['passed']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtraings = scaler.fit_transform(xtraings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalgs = scaler.transform(feat_val[strict_features])\n",
    "yvalgs = feat_val['passed']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': np.logspace(-3,3,7),\n",
    "    'penalty':[\"l1\", \"l2\"],\n",
    "    'random_state':[33]\n",
    "}\n",
    "score = make_scorer(recall_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.01, 'penalty': 'l1', 'random_state': 33}\n",
      "Best estimator:  LogisticRegression(C=0.01, penalty='l1', random_state=33, solver='saga')\n",
      "Training scores:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84     56369\n",
      "           1       0.56      0.17      0.26     20447\n",
      "\n",
      "    accuracy                           0.74     76816\n",
      "   macro avg       0.66      0.56      0.55     76816\n",
      "weighted avg       0.71      0.74      0.69     76816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(logreg, params, cv=5)\n",
    "gridsearch.fit(xtraings, ytraings)\n",
    "print(\"Best parameters: \", gridsearch.best_params_)\n",
    "\n",
    "best_estim=gridsearch.best_estimator_\n",
    "print(\"Best estimator: \",best_estim)\n",
    "\n",
    "best_estim.fit(xtraings, ytraings)\n",
    "\n",
    "ytr_pred = best_estim.predict(xtraings)\n",
    "print(\"Training scores: \", classification_report(ytraings, best_estim.predict(xtraings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13425,   667],\n",
       "       [ 4255,   857]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_preds = best_estim.predict(xvalgs)\n",
    "gs_conf = confusion_matrix(yvalgs, gs_preds)\n",
    "gs_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax = range(len(yvalgs))\n",
    "plt.scatter(x_ax, yvalgs, s=5, color='blue', label='original')\n",
    "plt.plot(x_ax, yvalgs, lw=0.8, color='red', label='predicted')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000, solver='saga')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline repeated with strict_features - \n",
    "lm_1 = LogisticRegression(solver='saga',  # same model as statsmodel,try default later\n",
    "                         C=100000)  # no regularization\n",
    "features = ['age', 'sex', 'patient_type', 'hypertension', 'obesity', 'inmsupr','copd', 'other_disease', 'renal_chronic','tobacco']\n",
    "X_train  = covid_feat[strict_features]\n",
    "y_train = covid_feat['passed']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "lm_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84     88077\n",
      "           1       0.56      0.18      0.27     31949\n",
      "\n",
      "    accuracy                           0.74    120026\n",
      "   macro avg       0.66      0.56      0.56    120026\n",
      "weighted avg       0.71      0.74      0.69    120026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training scores: \", classification_report(y_train, lm_1.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120026, 30)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sex', 'patient_type', 'entry_date', 'date_symptoms', 'date_died',\n",
       "       'intubed', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd',\n",
       "       'asthma', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular',\n",
       "       'obesity', 'renal_chronic', 'tobacco', 'contact_other_covid', 'icu',\n",
       "       'passed', 'comorb_count', 'imm_comorb', 'imm_covid_pos',\n",
       "       'imm_other_dis', 'imm_lung_disease', 'covid_res_1', 'covid_res_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex : [0.13623335]\n",
      "age : [0.60187323]\n",
      "pregnancy : [-0.08171028]\n",
      "diabetes : [0.07299871]\n",
      "copd : [-0.00296904]\n",
      "asthma : [-0.04281237]\n",
      "inmsupr : [0.]\n",
      "hypertension : [0.03932866]\n",
      "other_disease : [0.04393191]\n",
      "cardiovascular : [0.]\n",
      "obesity : [0.05849964]\n",
      "renal_chronic : [0.07024165]\n",
      "tobacco : [-0.00742825]\n",
      "contact_other_covid : [-0.21310149]\n",
      "comorb_count : [0.00056435]\n",
      "imm_comorb : [-0.00400084]\n",
      "imm_covid_pos : [0.]\n",
      "imm_other_dis : [0.]\n",
      "imm_lung_disease : [0.0554473]\n",
      "covid_res_1 : [0.47292332]\n",
      "covid_res_2 : [-0.12292091]\n"
     ]
    }
   ],
   "source": [
    "best_estim.coef_\n",
    "for feature, coef in zip(covid_feat[strict_features], best_estim.coef_.T):\n",
    "    print(feature, ':', coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
